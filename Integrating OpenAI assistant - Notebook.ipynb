{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integraing an OpenAI assistant with your application using Python\n",
    "\n",
    "When I was attending a hackathon at Cornell Univeristy, we were supposed to build an OpenAI assistant and upload documents so it could retrieve the information from those documents. However, OpenAI's documentation on running the assistant using Python looked very confusing to us. That's why I created this notebook to show how you can easily run an OpenAI assistant using Python without much confusion, and only in **3 simple steps**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import OpenAI (and other necessary modules relevant to your project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Create a thread\n",
    "We store the API key and Assistant ID to create a thread so that the conversation history is taken into account when new prompts come in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the API key and assistant ID \n",
    "openai.api_key = \"YOUR_API_KEY\"\n",
    "assistant_id = \"YOUR_ASSISTANT_ID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_thread(prompt):\n",
    "    \"\"\"\n",
    "    Creates a thread and run object\n",
    "    \n",
    "    params:\n",
    "        assistant_id (string): The OpenAI assistant ID available on the OpenAI assistant dashboard prompt\n",
    "\n",
    "    returns: run ID and thread ID as strings\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a thread\n",
    "    thread = openai.beta.threads.create()\n",
    "    my_thread_id = thread.id\n",
    "\n",
    "    # Create a message\n",
    "    message = openai.beta.threads.messages.create(\n",
    "        thread_id=my_thread_id,\n",
    "        role=\"user\",\n",
    "        content=prompt\n",
    "    )\n",
    "    # Create the run object\n",
    "    run = openai.beta.threads.runs.create(\n",
    "        thread_id=my_thread_id,\n",
    "        assistant_id=assistant_id,\n",
    "    ) \n",
    "    return run.id, thread.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Check the status\n",
    "We define the a function to check the response status to find out whether it is queued, failed, or any other status and, if necessary, take action in any specific status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_status(run_id,thread_id):\n",
    "    \"\"\"\n",
    "    Checks the status of run and whehter is queued, canceled, in progress, or other status\n",
    "\n",
    "    params:\n",
    "        run_id (string): The run ID received from create_thread\n",
    "        thread_id (string): The thread ID received from create_thread\n",
    "\n",
    "    returns: run status \n",
    "    \"\"\"\n",
    "\n",
    "    run = openai.beta.threads.runs.retrieve(\n",
    "        thread_id=thread_id,\n",
    "        run_id=run_id,\n",
    "    )\n",
    "    return run.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Get the Response\n",
    "The last step is define a function that returns the reponse from our OpenAI assistant. This function returns the reponse as a string and not its meta data. In case you want other information about the response, change the last return statement to just return `response` and that will return the entire reponse object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_response(prompt):\n",
    "    \"\"\"\n",
    "    Takes a prompt and returns the response from the assistant\n",
    "\n",
    "    params:\n",
    "        prompt (string): The prompt passed by the user to the assistant\n",
    "    \n",
    "    returns: The response that comes from the OpenAI assistant a string\n",
    "    \"\"\"\n",
    "\n",
    "    my_run_id, my_thread_id = create_thread(assistant_id, prompt)\n",
    "    status = check_status(my_run_id,my_thread_id)\n",
    "    while (status != \"completed\"):\n",
    "        status = check_status(my_run_id,my_thread_id)\n",
    "    response = openai.beta.threads.messages.list(\n",
    "    thread_id=my_thread_id\n",
    "    )\n",
    "    if response.data:\n",
    "        return response.data[0].content[0].text.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is all you need to intergate an OpenAI assistant with your program, and now you are able to do function calling, retrieval, and code interpreting. If you need any help in the process of the integrating the assistant with your application, reach out to me at `hr328@cornell.edu` and I will be happy to help. \n",
    "\n",
    "Happy integrating! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
